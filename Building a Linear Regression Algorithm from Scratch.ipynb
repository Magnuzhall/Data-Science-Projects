{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Welcome\n",
    "\n",
    "In this project we will be building a Linear Regression algorithm from scrath while at the same time explaning the concepts behind it\n",
    "\n",
    "With linear regression we are trying to find the line of best fit for our data, doing so will allow us to predict a given outcome based on the relationship between two variables. We can for example forecast sales based on previous months performance, try to predict the price for a property based on variables such as the number of square feet, number of bathrooms / bedrooms, estimate demand for a given product, forecast production capabilities, understand the relationship between customer complains and customer service wait times and many many other practical applications. \n",
    "\n",
    "Linear Regression is a great way of supporting business decisions by improving the accuracy and effectiveness of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to find the line of best fit, a line is determined by its Slope and its Intercept given y = mx + b\n",
    "\n",
    "Where y = given point on y axis, m = slope and b = intercept\n",
    "\n",
    "We are therefore tring to find the best m and b for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the model of best fit we must calculate loss, which is the squared distance from the line to each data point, our objective is to minimize the loss or in other words find the line which has the lowest sum of squared errors\n",
    "\n",
    "Lets dive into a quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [3, 5, 7]\n",
    "y = [3, 8, 11]\n",
    "\n",
    "#Let's set the slope and intercept\n",
    "m1 = 1\n",
    "b1 = 0\n",
    "\n",
    "#Now we'll find the y values that a line with the previous weights (m1 and b1) would predict. \n",
    "#We do this using a list comprehension and store these values in the variable y_prediction1\n",
    "y_prediction1 = [m1 * x + b1 for x in x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's set a second set to compare the results\n",
    "m2 = 0.5\n",
    "b2 = 1\n",
    "\n",
    "#And go through the same steps for this second set\n",
    "y_prediction2 = [m2 * x + b2 for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we find the sum of the squared distance between the predicted y values and the actual y values\n",
    "\n",
    "#A simple loop wil do the trick, this will calculate the difference between y and y prediction1, square the difference and add the total to the variable loss1 \n",
    "\n",
    "loss1 = 0\n",
    "for i in range(len(y)):\n",
    "  loss1 += (y[i] - y_prediction1[i]) ** 2\n",
    "\n",
    "#And do the same for the second set\n",
    "\n",
    "loss2 = 0\n",
    "for i in range(len(y)):\n",
    "  loss2 += (y[i] - y_prediction2[i]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 62.75\n"
     ]
    }
   ],
   "source": [
    "#Let's find out which line has the lowest loss\n",
    "print(loss1, loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Great, line 1 has definitely a lower average squared error = Is the line of best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onto our next steps: Gradient Descent\n",
    "\n",
    "Gradient means the slope of the curve, we want to move in the direction that minimizes loss the most, gradient descent will change/update each parameter to to minimize the cost function until it reaches a minimum point, in other words the model will predict the values of x in the best way it can\n",
    "\n",
    "###To get the gradient for b we use the following function. This used used to find the way the loss changes as the intercept of the line also changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we take a set of x and y values, a slope and an intercept\n",
    "def gradient_b(x, y, m, b):\n",
    "# Our goal is to go through all x and y values calculating (y - (m * x + b)) for each\n",
    "    sum_values = 0\n",
    "    N = len(x)\n",
    "    for i in range(N):\n",
    "        y_value = y[i]\n",
    "        x_value = x[i]\n",
    "        sum_values += x_value * (y_value - ((m * x_value) + b))\n",
    "    b_gradient = -2/N * sum_values\n",
    "    return b_gradient\n",
    "#For reference m = current gradient guess, b = current intercept guess, and N = number of points in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do the same for the slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_m(x, y, m, b):\n",
    "    sum_values = 0\n",
    "    N = len(x)\n",
    "    for i in range(N):\n",
    "        y_value = y[i]\n",
    "        x_value = x[i]\n",
    "        sum_values += x_value * (y_value - ((m * x_value) + b))\n",
    "    m_gradient = -2/N * sum_values\n",
    "    return m_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###We will now multiply the gradients by a learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will move our values towards a smallest loss each time \n",
    "def gradients(b_atm, m_atm, x, y, learning_rate):\n",
    "    b_gradient = gradient_b(x, y, b_atm, m_atm)\n",
    "    m_gradient = gradient_m(x, y, b_atm, m_atm)\n",
    "    b = b_atm - (0.01 * b_gradient)\n",
    "    m = m_atm - (0.01 * m_gradient)\n",
    "    return b, m\n",
    "#For reference: 0.01 = learning rate, b_atm and m_atm = the guess for the b and m values location and b_gradient and m_gradient are the gradients of the loss curve at the current guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Now how do we know when our model has learned enough or in other words when to stop changing the parameters?\n",
    "\n",
    "We do this by understanding convergence, which is when the loss changes very slowly or simply stops changing. We therefore want our model to converge at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for our model to run based on any given number of iterations, we want to move the b and m values in the direction of the gradients and in doing so find the best values\n",
    "\n",
    "To do this we will find the \"approximate\" best learning rate which will allow our model to converge. Based on the learning rate and number of iterations we define\n",
    "\n",
    "We will now create the gradient descent function which is the last step of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, learning_rate, iterations):\n",
    "    b = 0\n",
    "    m = 0\n",
    "#The loop will run a number of times at each step, we define the number and learning rate below\n",
    "    for i in range(iterations):\n",
    "        b, m = gradients(b, m, x, y, learning_rate)\n",
    "        return [b,m]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great that concludes our linear regression algorithm. \n",
    "\n",
    "This was just a step by a step project to build the algorithm from scratch, in the future we can import it from scikit learn with 2 simple lines\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Key takeaways:\n",
    "    \n",
    "The objective of linear regression is to minimize loss by finding the line of best fit\n",
    "\n",
    "We need both the slope (m) and intercept (b) to minimize the loss\n",
    "\n",
    "The algorithm reaches convergence when loss stops changing or changes very slowly. \n",
    "\n",
    "We change both the number of iterations and the learning rate to determine how much parameters are changed on each iteration\n",
    "\n",
    "Linear regression has a wide variety of practical business applications.\n",
    "\n",
    "###There are different kinds of regression algorithms which are best applied depending on the problem at hand, the most common are: \n",
    "\n",
    "Multiple linear regression\n",
    "\n",
    "Logistic regression \n",
    "\n",
    "Polynomial regression \n",
    "\n",
    "Ridge regression \n",
    "\n",
    "Lasso regression\n",
    "\n",
    "ElasticNet regression \n",
    "\n",
    "Stepwise regression\n",
    "\n",
    "We will cover some of these on future projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
