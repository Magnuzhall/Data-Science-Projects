{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Welcome\n",
    "\n",
    "In this project we will categorize emails using a Naive Bayes Classifier\n",
    "\n",
    "We will use different datasets to find out which kind of emails are harder to classify \n",
    "\n",
    "What exactly are we doing?\n",
    "\n",
    "The Bayes Theorem is a branch of statistics called Bayesian Statistics where we calculate probabilities based on prior knowledge of any given event or series of events. It has applications in A/B testing, Statistical Modeling, Machine Learning and Robotics. \n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B) This is the formula\n",
    "We can read it as: What is the probability of A given that B is true = The Probability of B given that A is true * Probability of A (all outcomes where A is true)/ Probability of B (all outcomes where B is true) \n",
    "\n",
    "\n",
    "We want to look at the text contained in different emails and calculate the probability of a series of words belonging to one or different topics in order to classify such emails (Example emails where the main topic is politics or the main topic is religion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first import our dataset and libraries to run the naive bayes classifier from scikit learn\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "#The dataset contains different kinds of emails\n",
    "emails = fetch_20newsgroups()\n",
    "\n",
    "print(emails.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to find out how accurate is our Naive Bayes classifier at knowing the difference between one type of email from the other, in this case hockey vs baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.sport.baseball', 'rec.sport.hockey']\n"
     ]
    }
   ],
   "source": [
    "#We assign to the variable emails only the two groups of emails we are interested in classifying\n",
    "emails_data = fetch_20newsgroups(categories = ['rec.sport.baseball', 'rec.sport.hockey'])\n",
    "print(emails_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: monack@helium.gas.uug.arizona.edu (david n monack)\n",
      "Subject: Re: ESPN Tonight\n",
      "Organization: University of Arizona - Tucson, Arizona\n",
      "Lines: 17\n",
      "\n",
      "In <1qkj1kINN3g1@master.cs.rose-hulman.edu> swartzjh@RoseVC.Rose-Hulman.Edu writes:\n",
      "\n",
      ">Has anyone heard what game ESPN is showing tonight.  They said they will\n",
      ">show whatever game means the most playoff-wise. I would assume this would\n",
      ">be the Blues-Tampa game or the Minnesota-Red Wings game...  Anyone heard for\n",
      ">sure???\n",
      "\n",
      ">\t\tJeff Swartz\n",
      "\n",
      "I heard it will be the Minnesota-Detroit game. Don't know the time\n",
      "though.\n",
      "\n",
      "Dave\n",
      "\n",
      "--\n",
      "David Monack        e-mail: monack@gas.uug.arizona.edu\n",
      "\"Love is the delusion that one woman differs from another.\" H.L. Mencken\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's check one of the emails in our dataset just to be sure\n",
    "print(emails_data.data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the emails have been previously labeled since this is the only way of training our supervised machine learning algorithm, lets find out if the previous email was labeled as hockey or baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Okay the previous was labeled as a hockey email\n",
    "print(emails_data.target[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now want to split our data for training\n",
    "\n",
    "emails_training = fetch_20newsgroups(categories = ['rec.sport.baseball', 'rec.sport.hockey'], subset = 'train', shuffle = True, random_state = 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now for testing\n",
    "\n",
    "emails_test = fetch_20newsgroups(categories = ['rec.sport.baseball', 'rec.sport.hockey'], subset = 'test', shuffle = True, random_state = 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We now transform the emails into word counts using the CountVectorizer function\n",
    "\n",
    "counter = CountVectorizer()\n",
    "\n",
    "#Then tell the function all the possible words in our dataset\n",
    "\n",
    "counter.fit(emails_test.data + emails_training.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's now make a list of the counts of words in our training and test sets\n",
    "\n",
    "training_count = counter.transform(emails_training.data)\n",
    "test_count = counter.transform(emails_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, time to make our Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we create an object out of the MutinomialNB scikit learn library\n",
    "\n",
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we fit in the data specifying the training set and the labels\n",
    "\n",
    "classifier.fit(training_count, emails_training.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Okay time to check how accurate is our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9723618090452262\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(test_count, emails_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Great! We achieved a 97.2% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our classifier one more time with 2 different kinds of emails\n",
    "\n",
    "We will choose politics and religion = 'talk.politics.misc', 'talk.religion.misc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split our data for training and testing \n",
    "\n",
    "emails_training2 = fetch_20newsgroups(categories = ['talk.politics.misc', 'talk.religion.misc'], subset = 'train', shuffle = True, random_state = 108)\n",
    "\n",
    "emails_test2 = fetch_20newsgroups(categories = ['talk.politics.misc', 'talk.religion.misc'], subset = 'test', shuffle = True, random_state = 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Naive Bayes Classifier\n",
    "\n",
    "counter2 = CountVectorizer()\n",
    "\n",
    "#Tell the function the vocabulary\n",
    "counter2.fit(emails_test2.data + emails_training2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of the counts of words in our training and test sets\n",
    "\n",
    "training_count2 = counter.transform(emails_training2.data)\n",
    "test_count2 = counter.transform(emails_test2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object from scikit learn library\n",
    "\n",
    "classifier2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit in the data specifying the training set and the labels\n",
    "\n",
    "classifier2.fit(training_count2, emails_training2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8805704099821747\n"
     ]
    }
   ],
   "source": [
    "#Check accuracy\n",
    "print(classifier2.score(test_count2, emails_test2.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The classifier is less accurate distinguishing between politics and religion emails, yet 88% is still quite good for the purpose of this project\n",
    "\n",
    "Thank you for reading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
